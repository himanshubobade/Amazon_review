{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15f8988b",
   "metadata": {},
   "source": [
    "# Question 1 - Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3997b1e9",
   "metadata": {},
   "source": [
    "### Importing all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3a0bafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import re\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb333813",
   "metadata": {},
   "source": [
    "### Downloading and extracting dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f26ecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Not present\n"
     ]
    }
   ],
   "source": [
    "# Specify path\n",
    "path = \"amazon_reviews_us_Office_Products_v1_00.tsv.gz\"\n",
    "\n",
    "# Check whether the specified\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "    print(\"Dataset file Not present\")\n",
    "    # Download the dataset file from given link in the assignment\n",
    "    \n",
    "    file_url = \"https://web.archive.org/web/20201127142707if_/https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Office_Products_v1_00.tsv.gz\"\n",
    "\n",
    "    # Specify the local file name where you want to save the downloaded file\n",
    "    local_file_name = \"amazon_reviews_us_Office_Products_v1_00.tsv.gz\"\n",
    "\n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(file_url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Open the local file in binary write mode and write the content of the response to it\n",
    "        with open(local_file_name, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "            print(f\"File '{local_file_name}' has been downloaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "        \n",
    "# Unzip the file\n",
    "with gzip.open(\"amazon_reviews_us_Office_Products_v1_00.tsv.gz\", 'rb') as gzipped_file, open(\"amazon_reviews_us_Office_Products_v1_00.tsv\", 'wb') as output:\n",
    "    # Read the compressed content and write it to the output file\n",
    "    output.write(gzipped_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9010a680",
   "metadata": {},
   "source": [
    "### Unzipping the downloaded compressed dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fde13a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"amazon_reviews_us_Office_Products_v1_00.tsv.gz\", 'rb') as gzipped_file, open(\"amazon_reviews_us_Office_Products_v1_00.tsv\", 'wb') as output:\n",
    "    # Read the compressed content and write it to the output file\n",
    "    output.write(gzipped_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94856d33",
   "metadata": {},
   "source": [
    "### Read and removed malicious rows from the .tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59e45576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHUU\\AppData\\Local\\Temp\\ipykernel_20084\\3440540034.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dff1 = pd.read_csv(\"amazon_reviews_us_Office_Products_v1_00.tsv\",sep='\\t', on_bad_lines='skip')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>43081963</td>\n",
       "      <td>R18RVCKGH1SSI9</td>\n",
       "      <td>B001BM2MAC</td>\n",
       "      <td>307809868</td>\n",
       "      <td>Scotch Cushion Wrap 7961, 12 Inches x 100 Feet</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great product.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>10951564</td>\n",
       "      <td>R3L4L6LW1PUOFY</td>\n",
       "      <td>B00DZYEXPQ</td>\n",
       "      <td>75004341</td>\n",
       "      <td>Dust-Off Compressed Gas Duster, Pack of 4</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Phffffffft, Phfffffft. Lots of air, and it's C...</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>21143145</td>\n",
       "      <td>R2J8AWXWTDX2TF</td>\n",
       "      <td>B00RTMUHDW</td>\n",
       "      <td>529689027</td>\n",
       "      <td>Amram Tagger Standard Tag Attaching Tagging Gu...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>but I am sure I will like it.</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>52782374</td>\n",
       "      <td>R1PR37BR7G3M6A</td>\n",
       "      <td>B00D7H8XB6</td>\n",
       "      <td>868449945</td>\n",
       "      <td>AmazonBasics 12-Sheet High-Security Micro-Cut ...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and the shredder was dirty and the bin was par...</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>24045652</td>\n",
       "      <td>R3BDDDZMZBZDPU</td>\n",
       "      <td>B001XCWP34</td>\n",
       "      <td>33521401</td>\n",
       "      <td>Derwent Colored Pencils, Inktense Ink Pencils,...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     43081963  R18RVCKGH1SSI9  B001BM2MAC       307809868   \n",
       "1          US     10951564  R3L4L6LW1PUOFY  B00DZYEXPQ        75004341   \n",
       "2          US     21143145  R2J8AWXWTDX2TF  B00RTMUHDW       529689027   \n",
       "3          US     52782374  R1PR37BR7G3M6A  B00D7H8XB6       868449945   \n",
       "4          US     24045652  R3BDDDZMZBZDPU  B001XCWP34        33521401   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0     Scotch Cushion Wrap 7961, 12 Inches x 100 Feet  Office Products   \n",
       "1          Dust-Off Compressed Gas Duster, Pack of 4  Office Products   \n",
       "2  Amram Tagger Standard Tag Attaching Tagging Gu...  Office Products   \n",
       "3  AmazonBasics 12-Sheet High-Security Micro-Cut ...  Office Products   \n",
       "4  Derwent Colored Pencils, Inktense Ink Pencils,...  Office Products   \n",
       "\n",
       "  star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0           5            0.0          0.0    N                 Y   \n",
       "1           5            0.0          1.0    N                 Y   \n",
       "2           5            0.0          0.0    N                 Y   \n",
       "3           1            2.0          3.0    N                 Y   \n",
       "4           4            0.0          0.0    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                                         Five Stars   \n",
       "1  Phffffffft, Phfffffft. Lots of air, and it's C...   \n",
       "2                      but I am sure I will like it.   \n",
       "3  and the shredder was dirty and the bin was par...   \n",
       "4                                         Four Stars   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0                                     Great product.  2015-08-31  \n",
       "1  What's to say about this commodity item except...  2015-08-31  \n",
       "2    Haven't used yet, but I am sure I will like it.  2015-08-31  \n",
       "3  Although this was labeled as &#34;new&#34; the...  2015-08-31  \n",
       "4                    Gorgeous colors and easy to use  2015-08-31  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff1 = pd.read_csv(\"amazon_reviews_us_Office_Products_v1_00.tsv\",sep='\\t', on_bad_lines='skip')\n",
    "dff1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee79a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the \"reviews\" and \"rating\" columns\n",
    "dff1 = dff1[['star_rating', 'review_headline','review_body']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a15344",
   "metadata": {},
   "source": [
    "### The datatype for star_rating is object as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "116009dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star_rating        object\n",
       "review_headline    object\n",
       "review_body        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b074cf13",
   "metadata": {},
   "source": [
    "### Changing the datatype of the column to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b35183a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star_rating        float64\n",
       "review_headline     object\n",
       "review_body         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to float datatype\n",
    "dff1['star_rating'] = pd.to_numeric(dff1['star_rating'], errors='coerce')\n",
    "dff1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1510b926",
   "metadata": {},
   "source": [
    "### Randomizing the rows and balancing the number of rows for creating a dataset with length 50,000 which for the classification sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d537487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dff1[dff1['star_rating'] == 1].sample(8333, random_state=42)\n",
    "df2 = dff1[dff1['star_rating'] == 2].sample(8333, random_state=42)\n",
    "df3 = dff1[dff1['star_rating'] == 3].sample(8334, random_state=42)\n",
    "df4 = dff1[dff1['star_rating'] == 4].sample(12500, random_state=42)\n",
    "df5 = dff1[dff1['star_rating'] == 5].sample(12500, random_state=42)\n",
    "\n",
    "# Concatenate the DataFrames into a new DataFrame df\n",
    "df = pd.concat([df1, df2, df3, df4, df5], ignore_index=True)\n",
    "\n",
    "# Shuffle the rows to ensure randomness\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Reset the index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4275f15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Great label printer</td>\n",
       "      <td>The usage is quite low but works great. The fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>I do like that it is black though I thought it...</td>\n",
       "      <td>This is one of the thinnest most cheaply made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Horrible and cheap</td>\n",
       "      <td>Horrible. No instruction manual to put it toge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Cracked in 5 Months</td>\n",
       "      <td>Lasted only 5 months before cracking.  And my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Awesome bag!</td>\n",
       "      <td>Always a great bag!! I use this for my college...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                    review_headline  \\\n",
       "0          4.0                                Great label printer   \n",
       "1          2.0  I do like that it is black though I thought it...   \n",
       "2          1.0                                 Horrible and cheap   \n",
       "3          2.0                                Cracked in 5 Months   \n",
       "4          5.0                                       Awesome bag!   \n",
       "\n",
       "                                         review_body  \n",
       "0  The usage is quite low but works great. The fa...  \n",
       "1  This is one of the thinnest most cheaply made ...  \n",
       "2  Horrible. No instruction manual to put it toge...  \n",
       "3  Lasted only 5 months before cracking.  And my ...  \n",
       "4  Always a great bag!! I use this for my college...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a52cf",
   "metadata": {},
   "source": [
    "# Question 2 - Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b32ba69",
   "metadata": {},
   "source": [
    "### Converting datatype to string and calculating length of review body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c132204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_length_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>great label printer</td>\n",
       "      <td>the usage is quite low but works great. the fa...</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>i do like that it is black though i thought it...</td>\n",
       "      <td>this is one of the thinnest most cheaply made ...</td>\n",
       "      <td>837.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>horrible and cheap</td>\n",
       "      <td>horrible. no instruction manual to put it toge...</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>cracked in 5 months</td>\n",
       "      <td>lasted only 5 months before cracking.  and my ...</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>awesome bag!</td>\n",
       "      <td>always a great bag!! i use this for my college...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                    review_headline  \\\n",
       "0          4.0                                great label printer   \n",
       "1          2.0  i do like that it is black though i thought it...   \n",
       "2          1.0                                 horrible and cheap   \n",
       "3          2.0                                cracked in 5 months   \n",
       "4          5.0                                       awesome bag!   \n",
       "\n",
       "                                         review_body  review_length_before  \n",
       "0  the usage is quite low but works great. the fa...                 139.0  \n",
       "1  this is one of the thinnest most cheaply made ...                 837.0  \n",
       "2  horrible. no instruction manual to put it toge...                  78.0  \n",
       "3  lasted only 5 months before cracking.  and my ...                 106.0  \n",
       "4  always a great bag!! i use this for my college...                 100.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the length of each review and store it in a new column\n",
    "df['review_length_before_data_cleaning'] = df['review_body'].str.len()\n",
    "\n",
    "# Converting to string datatype\n",
    "df['review_body'] = df['review_body'].astype(str)\n",
    "df['review_headline'] = df['review_headline'].astype(str)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbfc36b",
   "metadata": {},
   "source": [
    "### Applying data cleaning steps - lowercase + html/url removal + non aplhabetical character removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ffc5972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_length_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>great label printer</td>\n",
       "      <td>the usage is quite low but works great the fac...</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>i do like that it is black though i thought it...</td>\n",
       "      <td>this is one of the thinnest most cheaply made ...</td>\n",
       "      <td>837.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>horrible and cheap</td>\n",
       "      <td>horrible no instruction manual to put it toget...</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>cracked in  months</td>\n",
       "      <td>lasted only  months before cracking  and my ca...</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>awesome bag</td>\n",
       "      <td>always a great bag i use this for my college t...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                    review_headline  \\\n",
       "0          4.0                                great label printer   \n",
       "1          2.0  i do like that it is black though i thought it...   \n",
       "2          1.0                                 horrible and cheap   \n",
       "3          2.0                                 cracked in  months   \n",
       "4          5.0                                        awesome bag   \n",
       "\n",
       "                                         review_body  review_length_before  \n",
       "0  the usage is quite low but works great the fac...                 139.0  \n",
       "1  this is one of the thinnest most cheaply made ...                 837.0  \n",
       "2  horrible no instruction manual to put it toget...                  78.0  \n",
       "3  lasted only  months before cracking  and my ca...                 106.0  \n",
       "4  always a great bag i use this for my college t...                 100.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting all reviews into lowercase\n",
    "df['review_body'] = df['review_body'].str.lower()\n",
    "df['review_headline'] = df['review_headline'].str.lower()\n",
    "\n",
    "# Function to remove HTML tags using regular expressions\n",
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "# Function to remove URLs using regular expressions\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "\n",
    "# Clean the 'review_body' column\n",
    "df['review_body'] = df['review_body'].apply(remove_html_tags)\n",
    "df['review_body'] = df['review_body'].apply(remove_urls)\n",
    "\n",
    "# Cleaning the review_headline column\n",
    "df['review_headline'] = df['review_headline'].apply(remove_html_tags)\n",
    "df['review_headline'] = df['review_headline'].apply(remove_urls)\n",
    "\n",
    "# Remove non-alphabetical characters from the \"reviews\" column\n",
    "df['review_body'] = df['review_body'].str.replace('[^a-zA-Z\\s]', '', regex=True)\n",
    "df['review_headline'] = df['review_headline'].str.replace('[^a-zA-Z\\s]', '', regex=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba4dd05",
   "metadata": {},
   "source": [
    "### Extra space removal and contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "390aaf61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_length_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>great label printer</td>\n",
       "      <td>the usage is quite low but works great the fac...</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>i do like that it is black though i thought it...</td>\n",
       "      <td>this is one of the thinnest most cheaply made ...</td>\n",
       "      <td>837.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>horrible and cheap</td>\n",
       "      <td>horrible no instruction manual to put it toget...</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>cracked in months</td>\n",
       "      <td>lasted only months before cracking and my carp...</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>awesome bag</td>\n",
       "      <td>always a great bag i use this for my college t...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                    review_headline  \\\n",
       "0          4.0                                great label printer   \n",
       "1          2.0  i do like that it is black though i thought it...   \n",
       "2          1.0                                 horrible and cheap   \n",
       "3          2.0                                  cracked in months   \n",
       "4          5.0                                        awesome bag   \n",
       "\n",
       "                                         review_body  review_length_before  \n",
       "0  the usage is quite low but works great the fac...                 139.0  \n",
       "1  this is one of the thinnest most cheaply made ...                 837.0  \n",
       "2  horrible no instruction manual to put it toget...                  78.0  \n",
       "3  lasted only months before cracking and my carp...                 106.0  \n",
       "4  always a great bag i use this for my college t...                 100.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove extra spaces from the \"reviews\" column\n",
    "df['review_body'] = df['review_body'].str.replace('\\s+', ' ', regex=True)\n",
    "df['review_headline'] = df['review_headline'].str.replace('\\s+', ' ', regex=True)\n",
    "\n",
    "\n",
    "## Contractions ##\n",
    "\n",
    "# Function to expand contractions\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "# Apply the function to the \"reviews\" column\n",
    "df['review_body'] = df['review_body'].apply(expand_contractions)\n",
    "df['review_headline'] = df['review_headline'].apply(expand_contractions)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07439564",
   "metadata": {},
   "source": [
    "### Calculating average length of review_body column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c95cb887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_length_before</th>\n",
       "      <th>review_length_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>great label printer</td>\n",
       "      <td>the usage is quite low but works great the fac...</td>\n",
       "      <td>139.0</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>i do like that it is black though i thought it...</td>\n",
       "      <td>this is one of the thinnest most cheaply made ...</td>\n",
       "      <td>837.0</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>horrible and cheap</td>\n",
       "      <td>horrible no instruction manual to put it toget...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>cracked in months</td>\n",
       "      <td>lasted only months before cracking and my carp...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>awesome bag</td>\n",
       "      <td>always a great bag i use this for my college t...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                    review_headline  \\\n",
       "0          4.0                                great label printer   \n",
       "1          2.0  i do like that it is black though i thought it...   \n",
       "2          1.0                                 horrible and cheap   \n",
       "3          2.0                                  cracked in months   \n",
       "4          5.0                                        awesome bag   \n",
       "\n",
       "                                         review_body  review_length_before  \\\n",
       "0  the usage is quite low but works great the fac...                 139.0   \n",
       "1  this is one of the thinnest most cheaply made ...                 837.0   \n",
       "2  horrible no instruction manual to put it toget...                  78.0   \n",
       "3  lasted only months before cracking and my carp...                 106.0   \n",
       "4  always a great bag i use this for my college t...                 100.0   \n",
       "\n",
       "   review_length_after  \n",
       "0                  136  \n",
       "1                  828  \n",
       "2                   75  \n",
       "3                   99  \n",
       "4                   95  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the length of each review and store it in a new column\n",
    "df['review_length_after_data_cleaning'] = df['review_body'].str.len()\n",
    "\n",
    "# Calculate the average length of reviews\n",
    "average_length_before_data_cleaning = df['review_length_before_data_cleaning'].mean()\n",
    "\n",
    "# Calculate the average length of reviews\n",
    "average_length_after_data_cleaning = df['review_length_after_data_cleaning'].mean()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb29c1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average length before and after is :  333.8094847587807 316.61558  respectively\n"
     ]
    }
   ],
   "source": [
    "print(\"The average length before and after is data cleaning : \", average_length_before_data_cleaning, \" , \",average_length_after_data_cleaning, \" respectively\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181487e4",
   "metadata": {},
   "source": [
    "# Question 3 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b3ff0c",
   "metadata": {},
   "source": [
    "### Stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "432904e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HIMANSHUU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_length_before</th>\n",
       "      <th>review_length_after</th>\n",
       "      <th>review_length_after_preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>great label printer</td>\n",
       "      <td>usage quite low works great fact symbols well ...</td>\n",
       "      <td>139.0</td>\n",
       "      <td>136</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>i do like that it is black though i thought it...</td>\n",
       "      <td>one thinnest cheaply made door hooks ever seen...</td>\n",
       "      <td>837.0</td>\n",
       "      <td>828</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>horrible and cheap</td>\n",
       "      <td>horrible instruction manual put together looke...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>75</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>cracked in months</td>\n",
       "      <td>lasted months cracking carpet thick looking st...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>99</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>awesome bag</td>\n",
       "      <td>always great bag use college teaching goes ter...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                    review_headline  \\\n",
       "0          4.0                                great label printer   \n",
       "1          2.0  i do like that it is black though i thought it...   \n",
       "2          1.0                                 horrible and cheap   \n",
       "3          2.0                                  cracked in months   \n",
       "4          5.0                                        awesome bag   \n",
       "\n",
       "                                         review_body  review_length_before  \\\n",
       "0  usage quite low works great fact symbols well ...                 139.0   \n",
       "1  one thinnest cheaply made door hooks ever seen...                 837.0   \n",
       "2  horrible instruction manual put together looke...                  78.0   \n",
       "3  lasted months cracking carpet thick looking st...                 106.0   \n",
       "4  always great bag use college teaching goes ter...                 100.0   \n",
       "\n",
       "   review_length_after  review_length_after_preprocessing  \n",
       "0                  136                                 86  \n",
       "1                  828                                463  \n",
       "2                   75                                 59  \n",
       "3                   99                                 56  \n",
       "4                   95                                 63  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK stop words if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define a function to remove stop words from a text\n",
    "def remove_stopwords(text):\n",
    "    # Tokenize the text\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    # Join the filtered words back into a sentence\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply the function to the \"review_body\" column\n",
    "df['review_body'] = df['review_body'].apply(remove_stopwords)\n",
    "\n",
    "# Print the modified DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e798ef",
   "metadata": {},
   "source": [
    "### After lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed4dfb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HIMANSHUU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HIMANSHUU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_length_before</th>\n",
       "      <th>review_length_after</th>\n",
       "      <th>review_length_after_preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>great label printer</td>\n",
       "      <td>usage quite low work great fact symbol well us...</td>\n",
       "      <td>139.0</td>\n",
       "      <td>136</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>i do like that it is black though i thought it...</td>\n",
       "      <td>one thinnest cheaply made door hook ever seen ...</td>\n",
       "      <td>837.0</td>\n",
       "      <td>828</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>horrible and cheap</td>\n",
       "      <td>horrible instruction manual put together looke...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>75</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>cracked in months</td>\n",
       "      <td>lasted month cracking carpet thick looking str...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>99</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>awesome bag</td>\n",
       "      <td>always great bag use college teaching go terra...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                    review_headline  \\\n",
       "0          4.0                                great label printer   \n",
       "1          2.0  i do like that it is black though i thought it...   \n",
       "2          1.0                                 horrible and cheap   \n",
       "3          2.0                                  cracked in months   \n",
       "4          5.0                                        awesome bag   \n",
       "\n",
       "                                         review_body  review_length_before  \\\n",
       "0  usage quite low work great fact symbol well us...                 139.0   \n",
       "1  one thinnest cheaply made door hook ever seen ...                 837.0   \n",
       "2  horrible instruction manual put together looke...                  78.0   \n",
       "3  lasted month cracking carpet thick looking str...                 106.0   \n",
       "4  always great bag use college teaching go terra...                 100.0   \n",
       "\n",
       "   review_length_after  review_length_after_preprocessing  \n",
       "0                  136                                 86  \n",
       "1                  828                                463  \n",
       "2                   75                                 59  \n",
       "3                   99                                 56  \n",
       "4                   95                                 63  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Define a function to remove stop words and perform lemmatization\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    \n",
    "    # Join the lemmatized words back into a sentence\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Apply the function to the \"review_body\" column\n",
    "df['review_body'] = df['review_body'].apply(preprocess_text)\n",
    "\n",
    "# Print the modified DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8749d10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average length before and after is preprocessing:  316.61558 , 196.09036  respectively\n"
     ]
    }
   ],
   "source": [
    "# Calculate the length of each review and store it in a new column\n",
    "df['review_length_after_preprocessing'] = df['review_body'].str.len()\n",
    "\n",
    "# Calculate the average length of reviews\n",
    "average_length_after_data_preprocessing = df['review_length_after_preprocessing'].mean()\n",
    "print(\"The average length before and after is preprocessing: \", average_length_after_data_cleaning,\",\", average_length_after_data_preprocessing, \" respectively\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a0ab5d",
   "metadata": {},
   "source": [
    "# Question 4 - Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4efe240",
   "metadata": {},
   "source": [
    "### TF-IDF feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa5c41d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['review_body'])\n",
    "\n",
    "df['classes'] = df['star_rating'].apply(lambda x: 1 if x in [1.0, 2.0, 3.0] else 2)\n",
    "y_tfidf = df['classes']\n",
    "\n",
    "# Step 4: Split the data into training and testing sets\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y_tfidf, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "54c32b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_length_before</th>\n",
       "      <th>review_length_after</th>\n",
       "      <th>review_length_after_preprocessing</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>great label printer</td>\n",
       "      <td>usage quite low work great fact symbol well us...</td>\n",
       "      <td>139.0</td>\n",
       "      <td>136</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>i do like that it is black though i thought it...</td>\n",
       "      <td>one thinnest cheaply made door hook ever seen ...</td>\n",
       "      <td>837.0</td>\n",
       "      <td>828</td>\n",
       "      <td>458</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>horrible and cheap</td>\n",
       "      <td>horrible instruction manual put together looke...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>75</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>cracked in months</td>\n",
       "      <td>lasted month cracking carpet thick looking str...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>99</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>awesome bag</td>\n",
       "      <td>always great bag use college teaching go terra...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                    review_headline  \\\n",
       "0          4.0                                great label printer   \n",
       "1          2.0  i do like that it is black though i thought it...   \n",
       "2          1.0                                 horrible and cheap   \n",
       "3          2.0                                  cracked in months   \n",
       "4          5.0                                        awesome bag   \n",
       "\n",
       "                                         review_body  review_length_before  \\\n",
       "0  usage quite low work great fact symbol well us...                 139.0   \n",
       "1  one thinnest cheaply made door hook ever seen ...                 837.0   \n",
       "2  horrible instruction manual put together looke...                  78.0   \n",
       "3  lasted month cracking carpet thick looking str...                 106.0   \n",
       "4  always great bag use college teaching go terra...                 100.0   \n",
       "\n",
       "   review_length_after  review_length_after_preprocessing  classes  \n",
       "0                  136                                 82        2  \n",
       "1                  828                                458        1  \n",
       "2                   75                                 59        1  \n",
       "3                   99                                 55        1  \n",
       "4                   95                                 61        2  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc635bc3",
   "metadata": {},
   "source": [
    "### Bag of words feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bbd016be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create BoW features\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_BoW = count_vectorizer.fit_transform(df['review_body'])\n",
    "y_BoW = df['classes']  # Replace 'target_column' with the actual name of your target column\n",
    "\n",
    "# Step 4: Split the data into training and testing sets\n",
    "X_train_BoW, X_test_BoW, y_train_BoW, y_test_BoW = train_test_split(X_BoW, y_BoW, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d47d6c1",
   "metadata": {},
   "source": [
    "# Question 5 - Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa28052",
   "metadata": {},
   "source": [
    "### For TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "306c922b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_tfidf: 0.74\n",
      "Precision_tfidf (Training): 0.87\n",
      "Recall_tfidf (Training): 0.92\n",
      "F1-score_tfidf (Training): 0.90\n"
     ]
    }
   ],
   "source": [
    "# Perceptron model for TFIDF\n",
    "perceptron_model = Perceptron()\n",
    "perceptron_model.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_tfidf = perceptron_model.predict(X_test_tfidf)\n",
    "accuracy_tfidf = accuracy_score(y_test_tfidf, y_pred_tfidf)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for training data\n",
    "y_train_pred_tfidf = perceptron_model.predict(X_train_tfidf)\n",
    "precision_train_tfidf = precision_score(y_train_tfidf, y_train_pred_tfidf)\n",
    "recall_train_tfidf = recall_score(y_train_tfidf, y_train_pred_tfidf)\n",
    "f1_score_train_tfidf = f1_score(y_train_tfidf, y_train_pred_tfidf)\n",
    "\n",
    "print(f\"Accuracy_tfidf: {accuracy_tfidf:.2f}\")\n",
    "print(f\"Precision_tfidf (Training): {precision_train_tfidf:.2f}\")\n",
    "print(f\"Recall_tfidf (Training): {recall_train_tfidf:.2f}\")\n",
    "print(f\"F1-score_tfidf (Training): {f1_score_train_tfidf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd8ba0",
   "metadata": {},
   "source": [
    "### Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b613013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_BoW: 0.75\n",
      "Precision_BoW (Training): 0.85\n",
      "Recall_BoW (Training): 0.92\n",
      "F1-score_BoW (Training): 0.88\n"
     ]
    }
   ],
   "source": [
    "# Perceptron model for BoW\n",
    "perceptron_model = Perceptron()\n",
    "perceptron_model.fit(X_train_BoW, y_train_BoW)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_BoW = perceptron_model.predict(X_test_BoW)\n",
    "accuracy_BoW = accuracy_score(y_test_BoW, y_pred_BoW)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for training data\n",
    "y_train_pred_BoW = perceptron_model.predict(X_train_BoW)\n",
    "precision_train_BoW = precision_score(y_train_BoW, y_train_pred_BoW)\n",
    "recall_train_BoW = recall_score(y_train_BoW, y_train_pred_BoW)\n",
    "f1_score_train_BoW = f1_score(y_train_BoW, y_train_pred_BoW)\n",
    "\n",
    "print(f\"Accuracy_BoW: {accuracy_BoW:.2f}\")\n",
    "print(f\"Precision_BoW (Training): {precision_train_BoW:.2f}\")\n",
    "print(f\"Recall_BoW (Training): {recall_train_BoW:.2f}\")\n",
    "print(f\"F1-score_BoW (Training): {f1_score_train_BoW:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a86f3ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words -  0.8543916234282242 0.9151812537552574 0.883742294210081\n",
      "TFIDF -  0.8709280303030303 0.9209893851391949 0.8952594178915605\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of words - \",precision_train_BoW,recall_train_BoW,f1_score_train_BoW)\n",
    "print(\"TFIDF - \",precision_train_tfidf,recall_train_tfidf,f1_score_train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e2f8f1",
   "metadata": {},
   "source": [
    "# Question 6 - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c9b5f5",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "faee1d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Precision (Training): 0.87\n",
      "Recall (Training): 0.92\n",
      "F1-score (Training): 0.90\n"
     ]
    }
   ],
   "source": [
    "# Create an SVM model\n",
    "svm_model = SVC(kernel='linear')  # You can choose different kernels (e.g., 'linear', 'rbf', etc.) as per your needs\n",
    "\n",
    "# Train the SVM model on the training data\n",
    "svm_model.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "y_pred_tfidf_svm = svm_model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test_tfidf, y_pred_tfidf_svm)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for training data\n",
    "y_train_pred_tfidf_svm = svm_model.predict(X_train_tfidf)\n",
    "precision_train_tfidf_svm = precision_score(y_train_tfidf, y_train_pred_tfidf)\n",
    "recall_train_tfidf_svm = recall_score(y_train_tfidf, y_train_pred_tfidf)\n",
    "f1_score_train_tfidf_svm = f1_score(y_train_tfidf, y_train_pred_tfidf)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision (Training): {precision_train_tfidf_svm:.2f}\")\n",
    "print(f\"Recall (Training): {recall_train_tfidf_svm:.2f}\")\n",
    "print(f\"F1-score (Training): {f1_score_train_tfidf_svm:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f047047",
   "metadata": {},
   "source": [
    "### Bag of words with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8a66afd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n",
      "Precision (Training): 0.85\n",
      "Recall (Training): 0.92\n",
      "F1-score (Training): 0.88\n"
     ]
    }
   ],
   "source": [
    "# Create an SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Train the SVM model on the training data\n",
    "svm_model.fit(X_train_BoW, y_train_BoW)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "y_pred_BoW_svm = svm_model.predict(X_test_BoW)\n",
    "accuracy = accuracy_score(y_test_BoW, y_pred_BoW_svm)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for training data\n",
    "y_train_pred_BoW_svm = svm_model.predict(X_train_BoW)\n",
    "precision_train_BoW_svm = precision_score(y_train_BoW, y_train_pred_BoW)\n",
    "recall_train_BoW_svm = recall_score(y_train_BoW, y_train_pred_BoW)\n",
    "f1_score_train_BoW_svm = f1_score(y_train_BoW, y_train_pred_BoW)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision (Training): {precision_train_BoW_svm:.2f}\")\n",
    "print(f\"Recall (Training): {recall_train_BoW_svm:.2f}\")\n",
    "print(f\"F1-score (Training): {f1_score_train_BoW_svm:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4a6aef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words -  0.8543916234282242 0.9151812537552574 0.883742294210081\n",
      "TFIDF -  0.8709280303030303 0.9209893851391949 0.8952594178915605\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of words - \",precision_train_BoW_svm,recall_train_BoW_svm,f1_score_train_BoW_svm)\n",
    "print(\"TFIDF - \",precision_train_tfidf_svm,recall_train_tfidf_svm,f1_score_train_tfidf_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd644f4",
   "metadata": {},
   "source": [
    "# Question 7 - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c23be9d",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "00228c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy tfidf_lr: 0.81\n",
      "Precision tfidf_lr (Training): 0.85\n",
      "Recall tfidf_lr (Training): 0.86\n",
      "F1-score tfidf_lr (Training): 0.86\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Train the Logistic Regression model on the training data\n",
    "logistic_regression_model.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Evaluate the Logistic Regression model\n",
    "y_pred_tfidf_lr = logistic_regression_model.predict(X_test_tfidf)\n",
    "accuracy_tfidf_lr = accuracy_score(y_test_tfidf, y_pred_tfidf_lr)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for training data\n",
    "y_train_pred_tfidf_lr = logistic_regression_model.predict(X_train_tfidf)\n",
    "precision_train_tfidf_lr = precision_score(y_train_tfidf, y_train_pred_tfidf_lr)\n",
    "recall_train_tfidf_lr = recall_score(y_train_tfidf, y_train_pred_tfidf_lr)\n",
    "f1_score_train_tfidf_lr = f1_score(y_train_tfidf, y_train_pred_tfidf_lr)\n",
    "\n",
    "print(f\"Accuracy tfidf_lr: {accuracy_tfidf_lr:.2f}\")\n",
    "print(f\"Precision tfidf_lr (Training): {precision_train_tfidf_lr:.2f}\")\n",
    "print(f\"Recall tfidf_lr (Training): {recall_train_tfidf_lr:.2f}\")\n",
    "print(f\"F1-score tfidf_lr (Training): {f1_score_train_tfidf_lr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10912249",
   "metadata": {},
   "source": [
    "### Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2382d162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy BoW_lr: 0.80\n",
      "Precision BoW_lr (Training): 0.91\n",
      "Recall BoW_lr (Training): 0.88\n",
      "F1-score BoW_lr (Training): 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHUU\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create a Logistic Regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Step 3: Train the Logistic Regression model on the training data\n",
    "logistic_regression_model.fit(X_train_BoW, y_train_BoW)\n",
    "\n",
    "# Step 4: Evaluate the Logistic Regression model\n",
    "y_pred_BoW_lr = logistic_regression_model.predict(X_test_BoW)\n",
    "accuracy_BoW_lr = accuracy_score(y_test_BoW, y_pred_BoW_lr)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for training data\n",
    "y_train_pred_BoW_lr = logistic_regression_model.predict(X_train_BoW)\n",
    "precision_train_BoW_lr = precision_score(y_train_BoW, y_train_pred_BoW_lr)\n",
    "recall_train_BoW_lr = recall_score(y_train_BoW, y_train_pred_BoW_lr)\n",
    "f1_score_train_BoW_lr = f1_score(y_train_BoW, y_train_pred_BoW_lr)\n",
    "\n",
    "print(f\"Accuracy BoW_lr: {accuracy_BoW_lr:.2f}\")\n",
    "print(f\"Precision BoW_lr (Training): {precision_train_BoW_lr:.2f}\")\n",
    "print(f\"Recall BoW_lr (Training): {recall_train_BoW_lr:.2f}\")\n",
    "print(f\"F1-score BoW_lr (Training): {f1_score_train_BoW_lr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0a3340d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words -  0.9125051802735185 0.8819847786901662 0.8969854363988186\n",
      "TFIDF -  0.8521717547778606 0.8595533747246145 0.8558466485529826\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of words - \",precision_train_BoW_lr,recall_train_BoW_lr,f1_score_train_BoW_lr)\n",
    "print(\"TFIDF - \",precision_train_tfidf_lr,recall_train_tfidf_lr,f1_score_train_tfidf_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea272e29",
   "metadata": {},
   "source": [
    "# Question 8 - Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6b0267",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2546e941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_tfidf_NB: 0.78\n",
      "precision_train_tfidf_NB (Training): 0.83\n",
      "recall_train_tfidf_NB (Training): 0.87\n",
      "f1_score_train_tfidf_NB (Training): 0.85\n"
     ]
    }
   ],
   "source": [
    "# Create a Naive Bayes model (Multinomial Naive Bayes is commonly used for text classification)\n",
    "naive_bayes_model = MultinomialNB()\n",
    "\n",
    "# Train the Naive Bayes model on the training data\n",
    "naive_bayes_model.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Evaluate the Naive Bayes model\n",
    "y_pred_tfidf_NB = naive_bayes_model.predict(X_test_tfidf)\n",
    "accuracy_tfidf_NB = accuracy_score(y_test_tfidf, y_pred_tfidf_NB)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for training data\n",
    "y_train_pred_tfidf_NB = naive_bayes_model.predict(X_train_tfidf)\n",
    "precision_train_tfidf_NB = precision_score(y_train_tfidf, y_train_pred_tfidf_NB)\n",
    "recall_train_tfidf_NB = recall_score(y_train_tfidf, y_train_pred_tfidf_NB)\n",
    "f1_score_train_tfidf_NB = f1_score(y_train_tfidf, y_train_pred_tfidf_NB)\n",
    "\n",
    "print(f\"accuracy_tfidf_NB: {accuracy_tfidf_NB:.2f}\")\n",
    "print(f\"precision_train_tfidf_NB (Training): {precision_train_tfidf_NB:.2f}\")\n",
    "print(f\"recall_train_tfidf_NB (Training): {recall_train_tfidf_NB:.2f}\")\n",
    "print(f\"f1_score_train_tfidf_NB (Training): {f1_score_train_tfidf_NB:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2dd1b2",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f4434bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_BoW_NB: 0.78\n",
      "precision_train_BoW_NB (Training): 0.85\n",
      "recall_train_BoW_NB (Training): 0.79\n",
      "f1_score_train_BoW_NB (Training): 0.82\n"
     ]
    }
   ],
   "source": [
    "# Create a Naive Bayes model (Multinomial Naive Bayes is commonly used for text classification)\n",
    "naive_bayes_model = MultinomialNB()\n",
    "\n",
    "# Train the Naive Bayes model on the training data\n",
    "naive_bayes_model.fit(X_train_BoW, y_train_BoW)\n",
    "\n",
    "# Evaluate the Naive Bayes model\n",
    "y_pred_BoW_NB = naive_bayes_model.predict(X_test_BoW)\n",
    "accuracy_BoW_NB = accuracy_score(y_test_BoW, y_pred_BoW_NB)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for training data\n",
    "y_train_pred_BoW_NB = naive_bayes_model.predict(X_train_BoW)\n",
    "precision_train_BoW_NB = precision_score(y_train_BoW, y_train_pred_BoW_NB)\n",
    "recall_train_BoW_NB = recall_score(y_train_BoW, y_train_pred_BoW_NB)\n",
    "f1_score_train_BoW_NB = f1_score(y_train_BoW, y_train_pred_BoW_NB)\n",
    "\n",
    "print(f\"accuracy_BoW_NB: {accuracy_BoW_NB:.2f}\")\n",
    "print(f\"precision_train_BoW_NB (Training): {precision_train_BoW_NB:.2f}\")\n",
    "print(f\"recall_train_BoW_NB (Training): {recall_train_BoW_NB:.2f}\")\n",
    "print(f\"f1_score_train_BoW_NB (Training): {f1_score_train_BoW_NB:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d51400c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words -  0.853051996985682 0.793510915281394 0.8222049286640726\n",
      "TFIDF -  0.8253854599264882 0.8657620668936511 0.8450917621758999\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of words - \",precision_train_BoW_NB,recall_train_BoW_NB,f1_score_train_BoW_NB)\n",
    "print(\"TFIDF - \",precision_train_tfidf_NB,recall_train_tfidf_NB,f1_score_train_tfidf_NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f55d7b8",
   "metadata": {},
   "source": [
    "# The Final output for python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a4cebca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average length before data cleaning :  333.81\n",
      "The average length after data cleaning 316.62 \n",
      "\n",
      "The average length before preprocessing:  316.62\n",
      "The average length after  preprocessing:  196.09 \n",
      "\n",
      "Bag of words perceptron -  0.85\n",
      "TFIDF  perceptron-  0.87 \n",
      "\n",
      "Bag of words SVM-  0.85\n",
      "TFIDF SVM-  0.87 \n",
      "\n",
      "Bag of words Logistic regression -  0.91\n",
      "TFIDF Logistic regression -  0.85 \n",
      "\n",
      "Bag of words Naive bayes -  0.85\n",
      "TFIDF Naive bayes -  0.83 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The average length of characters in review_body before and after data cleaning\n",
    "print(\"The average length before data cleaning : \", \"{:.2f}\".format(average_length_before_data_cleaning))\n",
    "print(\"The average length after data cleaning\", \"{:.2f}\".format(average_length_after_data_cleaning), \"\\n\")\n",
    "\n",
    "# The average length of characters in review_body before and after preprocessing\n",
    "print(\"The average length before preprocessing: \", \"{:.2f}\".format(average_length_after_data_cleaning))\n",
    "print(\"The average length after  preprocessing: \",\"{:.2f}\".format(average_length_after_data_preprocessing),\"\\n\")\n",
    "\n",
    "# perceptron model precision, recall, f-1\n",
    "print(\"Bag of words perceptron - \",\"{:.2f}\".format(precision_train_BoW,recall_train_BoW,f1_score_train_BoW))\n",
    "print(\"TFIDF  perceptron- \",\"{:.2f}\".format(precision_train_tfidf,recall_train_tfidf,f1_score_train_tfidf),\"\\n\")\n",
    "\n",
    "# SVM precision, recall, f-1\n",
    "print(\"Bag of words SVM- \",\"{:.2f}\".format(precision_train_BoW_svm,recall_train_BoW_svm,f1_score_train_BoW_svm))\n",
    "print(\"TFIDF SVM- \",\"{:.2f}\".format(precision_train_tfidf_svm,recall_train_tfidf_svm,f1_score_train_tfidf_svm),\"\\n\")\n",
    "\n",
    "# LR precision, recall, f-1\n",
    "print(\"Bag of words Logistic regression - \",\"{:.2f}\".format(precision_train_BoW_lr,recall_train_BoW_lr,f1_score_train_BoW_lr))\n",
    "print(\"TFIDF Logistic regression - \",\"{:.2f}\".format(precision_train_tfidf_lr,recall_train_tfidf_lr,f1_score_train_tfidf_lr),\"\\n\")\n",
    "\n",
    "# Naive bayes precision, recall, f-1\n",
    "print(\"Bag of words Naive bayes - \",\"{:.2f}\".format(precision_train_BoW_NB,recall_train_BoW_NB,f1_score_train_BoW_NB))\n",
    "print(\"TFIDF Naive bayes - \",\"{:.2f}\".format(precision_train_tfidf_NB,recall_train_tfidf_NB,f1_score_train_tfidf_NB),\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
